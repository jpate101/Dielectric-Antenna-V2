{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d26e990",
   "metadata": {},
   "source": [
    "S1P_File_Finder Explanation \n",
    "\n",
    "this Scripts purpose is to corrolate s1p files to data.json files. the s1p files contain raw sensor readings and the data.json file contain labeling data for thoses s1p files. \n",
    "\n",
    "the script will save the information from these files into a format that can be used by the machine learning training scripts such as train_DNN.py\n",
    "\n",
    "that format will be base folder -> sub folder for each sample/datapoint -> 2 files - the s1p/raw sensor file and .json/file that contains the label information  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4808d7cc",
   "metadata": {},
   "source": [
    "import librarys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc2ec8",
   "metadata": {},
   "source": [
    "json_folder variable needs to be the filepath of the data.json folder/where the labeling data is stored. the filepath should be pointed at the output folder for the NN_Collect_V2 Script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your folder locations\n",
    "json_folder = r'C:\\Users\\JoshuaPaterson\\Phibion Pty Ltd\\IG88 - General\\03 Development\\Dielectric Antenna\\Predictive Model Training Guide and FIles\\Data Labeling Scripts\\Mt Weld Data D2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce1b41",
   "metadata": {},
   "source": [
    "s1p_folder variable needs to be the file path of the s1p files folder. this folder would have been generated by the VNA Sensor Python server. find the log file folder of the python server and then navigate to the vnaTouchstones folder within this folder there will be a folder containing vna readings or s1p files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98564270",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1p_folder = r'C:\\Users\\JoshuaPaterson\\Phibion Pty Ltd\\IG88 - General\\03 Development\\Dielectric Antenna\\Predictive Model Training Guide and FIles\\Data Labeling Scripts\\Mt Weld S1P - Day 2\\S1P Merge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b6be6",
   "metadata": {},
   "source": [
    "output_folder variable needs to be the file path of where you want the corrolated data to be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = r'C:\\Users\\JoshuaPaterson\\Phibion Pty Ltd\\IG88 - General\\03 Development\\Dielectric Antenna\\Predictive Model Training Guide and FIles\\Data Labeling Scripts\\MT_WELD_D2_OUTPUT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af1f0f",
   "metadata": {},
   "source": [
    "csv_file variable needs to be located at the csv/log file from the python server of the VNA sensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b16924",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = r'C:\\Users\\JoshuaPaterson\\Phibion Pty Ltd\\IG88 - General\\03 Development\\Dielectric Antenna\\Predictive Model Training Guide and FIles\\Data Labeling Scripts\\Mt Weld S1P - Day 2\\CSV_D2_Merge-WINJAMAICA-NS.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09461d7d",
   "metadata": {},
   "source": [
    "check the output_Folder location existance and initalises variables\n",
    "used_files_count and skipped_files_count which will hold the number of files skipped and used of the data.json file labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ecb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Counters for used and skipped files\n",
    "used_files_count = 0\n",
    "skipped_files_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383fcea2",
   "metadata": {},
   "source": [
    "takes the csv file located at csv_file variable and reads it into the programs memory to be accessed. specially saves the columns vna_filename and lat and long info. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV and build a dictionary for quick lookup by vna_filename\n",
    "csv_data = {}\n",
    "with open(csv_file, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        vna_filename = row['vna_filename']\n",
    "        gps_data = {\n",
    "            'latitude': row['latitude'],\n",
    "            'longitude': row['longitude']\n",
    "        }\n",
    "        csv_data[vna_filename] = gps_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9d119",
   "metadata": {},
   "source": [
    "function used to convert s1p file names into the same structure as the dates stored in the data.json label files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd138b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert timestamp to the format in the s1p filenames\n",
    "def convert_timestamp_to_filename_format(timestamp):\n",
    "    dt_obj = datetime.fromisoformat(timestamp)  # Parse the ISO format timestamp\n",
    "    return dt_obj.strftime('%Y-%m-%dT%H-%M-%S') + '.' + timestamp.split('.')[-1] + 'Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c033c",
   "metadata": {},
   "source": [
    "Function to compare timestamp data from data.json files and s1p files. checks to see if inputed timestamps are within a certain amount of time of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the timestamps are within a 30-second margin\n",
    "def is_within_margin(json_timestamp, s1p_timestamp, margin_seconds=20):\n",
    "    s1p_timestamp = s1p_timestamp.rstrip('Z')  # Remove 'Z' if it exists\n",
    "\n",
    "    # Ensure the timestamp is properly formatted with up to microseconds\n",
    "    if len(s1p_timestamp) > 26:\n",
    "        s1p_timestamp = s1p_timestamp[:26]  # Only keep the first 6 digits for microseconds\n",
    "\n",
    "    # Convert both JSON and S1P timestamps to datetime objects\n",
    "    try:\n",
    "        \n",
    "        json_time = datetime.strptime(json_timestamp, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "        s1p_time = datetime.strptime(s1p_timestamp, '%Y-%m-%dT%H-%M-%S.%f')  # Correct S1P timestamp format\n",
    "        \n",
    "        #s1p_time = s1p_time + timedelta(hours=10)\n",
    "        \n",
    "        #print(json_time)\n",
    "        #print(s1p_time)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing timestamps: {json_timestamp} and {s1p_timestamp}. Error: {e}\")\n",
    "        return False  # If we can't parse, return False (they don't match)\n",
    "\n",
    "    # Calculate the time difference in seconds\n",
    "    time_diff = abs((json_time - s1p_time).total_seconds())\n",
    "    \n",
    "    return time_diff <= margin_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed637b",
   "metadata": {},
   "source": [
    "Main body of Program\n",
    "\n",
    "loops through the data.json files with the label data and corrolates it to a compadiable s1p file (within 20 second) and lat and long value from the csv/log file from the vna sensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the JSON files\n",
    "for json_file_name in os.listdir(json_folder):\n",
    "    if json_file_name.endswith('.json'):\n",
    "        json_file_path = os.path.join(json_folder, json_file_name)\n",
    "        \n",
    "        # Open the JSON file and load its contents\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract the timestamp from the JSON file\n",
    "        json_timestamp = data.get('timestamp', '')\n",
    "        \n",
    "        # Print the timestamp of the current JSON file\n",
    "        print(f\"Processing JSON file: {json_file_name} with timestamp: {json_timestamp}\")\n",
    "        \n",
    "        # Convert the timestamp into the format used in the s1p filename\n",
    "        s1p_filename_base = convert_timestamp_to_filename_format(json_timestamp)\n",
    "        \n",
    "        # Search for corresponding S1P files with a 30-second margin\n",
    "        s1p_found = False\n",
    "        for s1p_file_name in os.listdir(s1p_folder):\n",
    "            if s1p_file_name.endswith('.s1p'):\n",
    "                s1p_file_path = os.path.join(s1p_folder, s1p_file_name)\n",
    "                \n",
    "                # Extract the timestamp portion from the S1P filename (assumed to be at the start)\n",
    "                s1p_timestamp_str = s1p_file_name.split('_')[0]  # Extract timestamp from the filename\n",
    "                \n",
    "                # Check if the timestamps are within the margin\n",
    "                if is_within_margin(json_timestamp, s1p_timestamp_str):\n",
    "                    # If the timestamps are within 30 seconds, copy both files\n",
    "                    \n",
    "                    # Create a new folder for the matching files\n",
    "                    new_folder = os.path.join(output_folder, os.path.splitext(json_file_name)[0])\n",
    "                    os.makedirs(new_folder, exist_ok=True)\n",
    "                    \n",
    "                    # Copy the JSON file as 'data.json'\n",
    "                    shutil.copy(json_file_path, os.path.join(new_folder, 'data.json'))\n",
    "                    \n",
    "                    # Get the corresponding GPS data from the CSV file\n",
    "                    gps_data = csv_data.get(s1p_file_name, None)\n",
    "                    \n",
    "                    if gps_data:\n",
    "                        # Update the JSON data with GPS info\n",
    "                        with open(os.path.join(new_folder, 'data.json'), 'r') as f:\n",
    "                            json_data = json.load(f)\n",
    "                        \n",
    "                        json_data.update(gps_data)\n",
    "                        \n",
    "                        # Save the updated data to data.json\n",
    "                        with open(os.path.join(new_folder, 'data.json'), 'w') as f:\n",
    "                            json.dump(json_data, f, indent=4)\n",
    "                    \n",
    "                    # Copy the S1P file\n",
    "                    shutil.copy(s1p_file_path, new_folder)\n",
    "                    \n",
    "                    print(f\"Copied: {json_file_name} (renamed to data.json) and {s1p_file_name} to {new_folder}\")\n",
    "                    \n",
    "                    s1p_found = True\n",
    "                    used_files_count += 1  # Increment the used files counter\n",
    "                    break\n",
    "        \n",
    "        if not s1p_found:\n",
    "            print(f\"Skipping {json_file_name}: No corresponding S1P file found within 20 seconds\")\n",
    "            skipped_files_count += 1  # Increment the skipped files counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2489f9",
   "metadata": {},
   "source": [
    "print the number of labels that found successfull corrolations and number that where skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final count of used and skipped files\n",
    "print(f\"\\nTotal used files: {used_files_count}\")\n",
    "print(f\"Total skipped files: {skipped_files_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
